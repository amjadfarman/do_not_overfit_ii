{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not overfit -- Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "train_data = pd.read_csv(f'{data_path}train.csv', index_col = 'id')\n",
    "test_data = pd.read_csv(f'{data_path}test.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89690</th>\n",
       "      <td>79</td>\n",
       "      <td>187</td>\n",
       "      <td>0.243916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89691</th>\n",
       "      <td>187</td>\n",
       "      <td>79</td>\n",
       "      <td>0.243916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89692</th>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0.244012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89693</th>\n",
       "      <td>187</td>\n",
       "      <td>140</td>\n",
       "      <td>0.244012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89694</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>0.246062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89695</th>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>0.246062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89696</th>\n",
       "      <td>193</td>\n",
       "      <td>101</td>\n",
       "      <td>0.252825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89697</th>\n",
       "      <td>101</td>\n",
       "      <td>193</td>\n",
       "      <td>0.252825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89698</th>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>0.259315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89699</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>0.259315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0 level_1         0\n",
       "89690      79     187  0.243916\n",
       "89691     187      79  0.243916\n",
       "89692     140     187  0.244012\n",
       "89693     187     140  0.244012\n",
       "89694      28      22  0.246062\n",
       "89695      22      28  0.246062\n",
       "89696     193     101  0.252825\n",
       "89697     101     193  0.252825\n",
       "89698      32      75  0.259315\n",
       "89699      75      32  0.259315"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs = train_data.drop(labels = ['target'], axis = 1).corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "corrs = corrs[corrs['level_0'] != corrs['level_1']]\n",
    "corrs.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    160\n",
       "0.0     90\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_impact = pd.DataFrame(\n",
    "    columns = ['column_name', 'mean_impact_on_0', 'mean_impact_on_1', 'std_0', 'std_1']\n",
    ")\n",
    "for col in train_data.columns[train_data.columns != 'target']:\n",
    "    columns_impact = columns_impact.append(dict(\n",
    "        column_name = col\n",
    "        , mean_impact_on_0 = train_data[train_data['target'] == 0][col].mean()\n",
    "        , mean_impact_on_1 = train_data[train_data['target'] == 1][col].mean()\n",
    "        , std_0 = train_data[train_data['target'] == 0][col].std()\n",
    "        , std_1 = train_data[train_data['target'] == 1][col].std()\n",
    "    )\n",
    "                                          , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33</th>\n",
       "      <th>65</th>\n",
       "      <th>82</th>\n",
       "      <th>129</th>\n",
       "      <th>226</th>\n",
       "      <th>245</th>\n",
       "      <th>91</th>\n",
       "      <th>63</th>\n",
       "      <th>182</th>\n",
       "      <th>287</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>142</th>\n",
       "      <th>165</th>\n",
       "      <th>98</th>\n",
       "      <th>143</th>\n",
       "      <th>271</th>\n",
       "      <th>6</th>\n",
       "      <th>76</th>\n",
       "      <th>272</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.655</td>\n",
       "      <td>-2.851</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.860</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.292</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-1.556</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>-1.320</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-1.516</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.721</td>\n",
       "      <td>1.221</td>\n",
       "      <td>0.406</td>\n",
       "      <td>1.111</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.188</td>\n",
       "      <td>1.808</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>0.053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.822</td>\n",
       "      <td>-2.771</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-1.181</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>1.843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-0.729</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-1.661</td>\n",
       "      <td>-0.727</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>1.492</td>\n",
       "      <td>0.346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>1.848</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.852</td>\n",
       "      <td>1.103</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.855</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>-2.284</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.272</td>\n",
       "      <td>2.725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-1.096</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.679</td>\n",
       "      <td>1.775</td>\n",
       "      <td>0.096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.932</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.585</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       33     65     82    129    226    245     91     63    182    287  \\\n",
       "id                                                                         \n",
       "0   0.385 -0.770 -0.380  0.278  0.655 -2.851  0.019  0.933  0.860 -0.284   \n",
       "1  -2.721  1.221  0.406  1.111 -0.124 -0.187  1.188  1.808 -0.607  0.053   \n",
       "2   0.924  0.943 -0.101  0.325 -1.181  0.779  0.269 -0.091 -0.083  1.843   \n",
       "3   0.394 -0.706  1.848 -0.630  1.069  1.852  1.103 -0.421  0.855 -0.299   \n",
       "4   0.037  0.357 -0.054 -0.062  0.204 -1.096  0.892  0.679  1.775  0.096   \n",
       "\n",
       "     ...       81    142    165     98    143    271      6     76    272  \\\n",
       "id   ...                                                                    \n",
       "0    ...    1.292 -0.067 -0.565 -1.556 -0.661 -1.320 -0.236  0.219 -1.516   \n",
       "1    ...   -0.661  0.495  0.166 -0.305 -0.822 -2.771  1.172  0.002 -0.516   \n",
       "2    ...   -0.031  0.149 -0.729  0.074 -1.661 -0.727 -0.023  1.492  0.346   \n",
       "3    ...    0.312  0.614 -0.824 -2.284 -0.268 -0.710 -1.035  0.272  2.725   \n",
       "4    ...   -0.932  0.472  0.134  0.749  0.949  0.055  0.585 -0.930 -0.464   \n",
       "\n",
       "    target  \n",
       "id          \n",
       "0      1.0  \n",
       "1      0.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_impact['difference_of_means'] = (columns_impact['mean_impact_on_0'] - columns_impact['mean_impact_on_1']).abs()\n",
    "columns_impact['conf_int_gap'] = columns_impact.apply(\n",
    "    lambda row:\n",
    "    (row['mean_impact_on_1'] - 2 * row['std_1']) - (row['mean_impact_on_0'] + 2 * row['std_0'])\n",
    "    if row['mean_impact_on_0'] < row['mean_impact_on_1']\n",
    "    else (row['mean_impact_on_0'] - 2 * row['std_0']) - (row['mean_impact_on_1'] + 2 * row['std_1'])\n",
    "    , axis=1\n",
    ")\n",
    "best_columns = list(\n",
    "    columns_impact.sort_values(by=['conf_int_gap', 'difference_of_means']\n",
    "                               , ascending = [False, False])['column_name'][:100]\n",
    ")\n",
    "train_data = train_data[best_columns + ['target']]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=0.781 auc=0.932 ap=0.932\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAF0BJREFUeJzt3Xuc3XV95/HXJxNCCDUkMMENuU2A\nIKRIkYwDqOESxI1sTR6ltIKrhZYlaotuLbbi4kMt7a7WXdat3awSWyTgQy6ytEY2iA8il4gJk0kR\nJIHAkAszhEIuCEKUQPjuH78z5MwlzC+Tc5nzm9fz8ZjHOef3+845n1/m5D3f+Z7v7/uLlBKSpGIZ\nVe8CJEmVZ7hLUgEZ7pJUQIa7JBWQ4S5JBWS4S1IBGe6SVECGuyQVkOEuSQU0ul4v3NzcnFpaWur1\n8pLUkNauXbs9pTRpsHZ1C/eWlhY6Ojrq9fKS1JAiYkuedg7LSFIBGe6SVECGuyQVkOEuSQVkuEtS\nAQ0a7hFxXUQ8HxGP7mN/RMQ3IqIzIh6JiFMqX6YkaX/k6blfD8x/i/0fBGaVvhYB3zzwst5CVzus\nvCa7tY1tKt1mONUiHYBB57mnlO6PiJa3aLIQuCFl1+tbHRETImJySunZCtW4V1c7XP+7sGc3jGqC\nkz4M46f0bvPSM/DILfDGHtvYZv/a1KuW0WPh4mUwrQ2pUiLPNVRL4X5HSunEAfbdAXw1pfTT0uMV\nwOdSSv3OUIqIRWS9e6ZPnz5ny5Zcc/H3WnkNrPgboLzm6NNooOOxjW3ytKlTLdEE866CuVcM8H1S\nbxGxNqXUOli7Spyh2vddCwO/u0kpLQGWALS2tu7/lblb5ma9nD27oWnMwL2drnZYusA2ttn/NrWu\n5TvnwRuvQdNB2XtbqqBK9NyvBe5NKd1UerwBOGuwYZnW1tY0pOUHutph88rsP8O+/oy1jW2G2qaW\ntdx1Faz63/CR78NxHxi4jdRH3p57JcL9PwCXA+cBpwLfSCkNOng45HCXiqL927D8s/CXT8GhzfWu\nRg2iYsMyEXETcBbQHBHdwJeAgwBSSt8ClpMFeyewC/jjoZctSaqEPLNlLhpkfwL+rGIVSZIOmGeo\nSlIBGe6SVECGuyQVkOEuSQVkuEtSARnuklRAhrskFZDhLkkFZLhLUgEZ7pJUQIa7JBWQ4S5JBWS4\nS1IBGe7ScOZFtDVElbjMnqSheGFzdrvhTjji2Oyi2S9tLX09A9uegO2PZ21GH+JFtLVfDHepHrra\n4cFrs/vLLu+9b8xvwfgpsOe1vdv27M4u22e4KyfDXaqHzSsh7Sk9GAUnXwTv+TSMPwrGjs82d7XD\ndz4Ib7zuRbS13xxzl+qhZS40HQzRBKMPhjmXwJHH7w12yHrpp/xRdv8/3mavXfvFnrtUD9PasjH0\nzSuzoN9XcB82Lbud+u7a1aZCMNylepnWZm9cVeOwjCQVkOEuSQVkuEtSARnuklRAhrskFZDhLkkF\nZLhLyu/pB+F+FzJrBM5zl5Tpas9OqprxPpgwHXY+BTueym53boR/exRe2JS1dSGzYc9wl0aCnuAu\nPxv21Zdhx5OwvRM23gMP3wTpjf7fO+ogmNgCTWVx4UJmw57hLhVZSvDEXXDrx7JVJmMUTD4JXn4+\nW1b4TQGkvfePmw9tl8ERx2RLIIxqyn5BXDc/W/CsaYwLmQ1zhrvU6Hp65W9/Jxx0CGx7HJ5/bO/t\nr3fubZv2wMvPQcsZ0DwLmo/LbnftgO9ekPXIm8bA3L/o3yuf1gYt74Xn1sNFN9lrH+YMd6nRvP4q\nbNsAzz0KT94N6/+5/3DKwYdlq0ye8CE4aBx0/BO8Uepx/8HSgYM5z0Jm446AcYcb7A3AcJeGsxe7\nstsfXQm7X8kCffsT2RrvAKNGlwV7wMkfgXlfgLdNhoi9z3Pi+YMHtwuZFYrhLg1XXe3wrzdm99d+\nB8Y1w5RTsvHwf3diNgyzawfc+Ht7h1PmXJJd8KMvg3vEMdyl4Wrzyr298miC0/8U5l7Rv12e4RSN\nOIa7NFy1zM164z298n3NTrFXrgHkOkM1IuZHxIaI6IyIKwfYPyMiVkTEIxFxb0RMrXyp0gjTc7Wm\neVd5wpD226A994hoAhYD5wLdwJqIWJZSWl/W7H8AN6SUlkbEPOArwMeqUbA0otgr1xDl6bm3AZ0p\npY0ppd3AzcDCPm1mAytK9+8ZYL8kqYbyhPsUoKvscXdpW7mHgd8v3f894G0RcUTfJ4qIRRHREREd\n27ZtG0q9kqQc8oR7DLAt9Xn8WeDMiHgIOBN4Bni93zeltCSl1JpSap00adJ+FytJyidPuHcD08oe\nTwW2ljdIKW1NKZ2fUnoXcFVp24sVq1LS8LBrB+za6ZK/DSBPuK8BZkXEzIgYA1wILCtvEBHNEdHz\nXJ8HrqtsmZLqrqsdNj8Au7bD0gUG/DA3aLinlF4HLgfuAh4Dbk0prYuIqyNiQanZWcCGiHgCeDvw\nX6tUr6R62bwyW3gM9i75q2Er10lMKaXlwPI+275Ydv824LbKliZpWGmZm50p65K/DcHL7EnKp2fJ\n33HNnlTVAAx3Sfm55G/DMNwlqYAMd0kqIMNdkgrIcJekAjLcJamADHdJKiDDXZIKyHCXpAIy3CXl\n56qQDcNwl5SPq0I2FMNdUj6uCtlQDHdJ+fSsCgmuCtkADHdJ+bgqZEMx3CXl56qQDcNwl6QCMtwl\nqYAMd0kqIMNdkgrIcJekAjLcJamADHdJKiDDXVJ+LhzWMAx3Sfm4cFhDMdwl5ePCYQ3FcJeUjwuH\nNRTDXVI+tV44rKsdVl7j8M8Qja53AZIaSLUXDksJdm6Ejutg9f/JHo8e6yqUQ2C4S6q9rvZszL5l\nLhxxLGy6D566BzbeA798unfbnvF9w32/GO6SamvLz+CGhbDntdKGlN0cPB5mngHv+XT2F8Jtf5Lt\nc3x/SAx3SdX30lbovBue/DE88eOsN95j5pkw7wtw1CnQVBZJP/lbGNUECxfbax8Cw11SZXW1w8b7\n4JCJ8FI3PHk3PPeLbN/4KXDMPHhqBbyxJ+uVz/vCwOE95tCsvcE+JIa7pMrYtRMevBbu/+9758NH\nE0w/Hd7/1zDrXDhyNkT0HnOvxaybWr3WMGK4Sxq6nRthw53Z15af7Q11gBgFZ1wBZ1/V//umtVV3\nxs22DbDxXlj3z9C1GogRN+vGcJeU364d2fj57R+HZx+GbY9l24+cDe/7c5jQAnf+VTam3jQGjj23\nuvX09Mqbj4dXX8wCfeN98PK/ZfsPmVhqmEbcrJtc4R4R84G/B5qAf0wpfbXP/unAUmBCqc2VKaXl\nFa5VUj31rC2T9sAjN8Pkk2H+V+G4+XD4zL3tjjy++sMgu1+BNdfBii9lY/c9xjXD0WfC0WdlH9S+\n/Bz807lAjLhZN4OGe0Q0AYuBc4FuYE1ELEsprS9r9gXg1pTSNyNiNrAcaKlCvZLqZfNK3py2GE0w\newGc9sn+7aox5JISPP9YNuPmqRXZEFD5jBsC2hZlv2xGlZ14P3FG1nufOBM++HcjptcO+XrubUBn\nSmkjQETcDCwEysM9AeNL9w8DtlaySEnDQMtcaDp475BLtXvBu1+BZzrgex+GZx+BX5ViZdIJWZAf\nNhXu/nI2X75pDLzzgt7B3qNpDEw+aUQFO+QL9ylAV9njbuDUPm2+DPw4Ij4FHAq8vyLVSRo+prVl\nH0jWYuZJVzu8sAnSG/DEj7LXO+tKOPacLNR7TJkzImfC5JEn3GOAbanP44uA61NK10TE6cCNEXFi\nSumNXk8UsQhYBDB9+vSh1Cupnqo5y6Vc+XLC0QTHnA1zLq5fPQ0oz6qQ3cC0ssdT6T/scilwK0BK\naRUwFmju+0QppSUppdaUUuukSZOGVrGk4usZAoqmEfdBaKXkCfc1wKyImBkRY4ALgWV92jwNnAMQ\nESeQhfu2ShYqaQTpGQKad9WBz03fszsbsx9hSwcPOiyTUno9Ii4H7iKb5nhdSmldRFwNdKSUlgFX\nAN+OiM+QDdlcklLqO3QjSflVYsilqx1+/UL2tXSBJzH1VZqzvrzPti+W3V8PvLeypUnSASofux9h\nJzF5JSZJxfXmWL0nMUlScUxrG7EnMdlzl1RsI/QkJsNdkgrIcJekAjLcJamADHdJKiDDXVKx1fIM\n1a52WHnNsDgb1qmQkoqrlmeorv8B/N9LSxf+PrjuZ8Ma7pKKq5pnqO7eBZt/ml08pPNu2NFZvdca\nAsNdUnFV8gzVpx+EdbdnPfMdT8KWVbDn1ezC2y3vg5lnQMd1lXmtCjDcJRXXgZ6huvuV7ILbD90I\nG+7kzUtZTJgBbZfBMfNgxnvgoEPg1ZezcD/2HDjzc3U/acpwl1Rsec5Q7Wrfe0WnQyfBkz+GJ+7K\nhl32vJo9R/n1Y+dcDHOvGPi5Zp5Z92AHw13SSLdlFdywILsWK/BmiB9+DLz7P8FxH4BRB8F3f792\n14+tAMNd0sjz6q+gcwVsWJ7Nctmze+++Wf8e5n8Fjjim9/fU6vqxFWK4Syq2nnnujy+HXz2bjZ1v\nui/bfsjELKw33VeawjgGzvhs/2CH/BcP2XQfTD+t7r8ADHdJxVU+z/3mi7JtE1vg3ZfB8efBtNOg\naXTvMfehhnJ3R3bbuQI2P+A8d0mqmvJ57gSc+olsyCWid7tKXNLv6VWlO2lYzHN3+QFJxdUyF0Yf\nks1wGT0WTjy/f7BXyvTTS3ec5y5J1TWtrXYfhE5tzW6d5y5JNVCJIZf9MUzmuTssI0kFZLhLUgEZ\n7pJUSZvuGxbruRvuklQJ5fPcly6oe8Ab7pJUCQPNc68jw12SKmGYzXM33CWpEsrnudd56QEw3CWp\nspznLkmqFsNdkirJqZCSVCBOhZSkAnIqpCQVkFMhJamA8k6F7GqHlddUfdjGJX8lqZL2NRXyV8/B\n6sXws3+ABIw+uKrz4XOFe0TMB/4eaAL+MaX01T77vw6cXXo4DjgypTShkoVKUsPZ3gmP3wGP/z/o\nXkOW6iVVvhTfoOEeEU3AYuBcoBtYExHLUkrre9qklD5T1v5TwLuqUKskDX/rbofn1sHWh2D7hmzb\n5N+Bs6+CCdPhh/85C/Yqj8vn6bm3AZ0ppY0AEXEzsBBYv4/2FwFfqkx5ktQgnlmb3W59KPuafDJ8\n8GvwjvNgwrS97Q6fWZPL/uUJ9ylAV9njbuDUgRpGxAxgJvCTAy9NkhrIMx1AACm7IPfsBXDqx/u3\nq9Fl//LMlhnoUuFpgG0AFwK3pZT2DPhEEYsioiMiOrZt25a3Rkka/lrmwuixWbAPg6mQeXru3UDZ\n3xRMBbbuo+2FwJ/t64lSSkuAJQCtra37+gUhSY1nWls2+6UGQy555An3NcCsiJgJPEMW4B/p2ygi\n3gFMBFb13SdJI0KNhlzyGHRYJqX0OnA5cBfwGHBrSmldRFwdEQvKml4E3JxSskcuSXWWa557Smk5\nsLzPti/2efzlypUlSToQLj8gSQVkuEtSARnuklRAhrskFZDhLkkFZLhLUgEZ7pJUQIa7JBWQ4S5J\nBWS4S1IBGe6SVECGuyQVkOEuSQVkuEtSARnuklRAhrskFZDhLkkFZLhLUgEZ7pJUQIa7JBWQ4S5J\nBWS4S1IBGe6SVECGuyQVkOEuSQVkuEtSARnuklRAhrskFZDhLkkFZLhLUgEZ7pJUQIa7JBWQ4S5J\nBWS4S1IBGe6SVECGuyQVUK5wj4j5EbEhIjoj4sp9tPnDiFgfEesi4nuVLVOStD9GD9YgIpqAxcC5\nQDewJiKWpZTWl7WZBXweeG9K6YWIOLJaBUuSBpen594GdKaUNqaUdgM3Awv7tLkMWJxSegEgpfR8\nZcuUJO2PPOE+Begqe9xd2lbuOOC4iHggIlZHxPxKFShJ2n+DDssAMcC2NMDzzALOAqYCKyPixJTS\nL3s9UcQiYBHA9OnT97tYSVI+eXru3cC0ssdTga0DtPlBSum1lNImYANZ2PeSUlqSUmpNKbVOmjRp\nqDVLkgaRJ9zXALMiYmZEjAEuBJb1afMvwNkAEdFMNkyzsZKFSpLyGzTcU0qvA5cDdwGPAbemlNZF\nxNURsaDU7C5gR0SsB+4B/jKltKNaRUuS3lqk1Hf4vDZaW1tTR0dHXV5bkhpVRKxNKbUO1s4zVCWp\ngAx3SSogw12SCshwl6QCMtwlqYAMd0kqIMNdkgrIcJekAjLcJamADHdJKiDDXZIKKM967sPOh69d\n1W/b7540mY+d3sKvd+/hku+099t/wZyp/EHrNHa+sptPfndtv/0fPW0GH/qdo9j6y1/zmVt+3m//\nZXOP5v2z385T217mv9z+i377PzVvFu+b1cy6rS9y9Q/X99v/V/PfwZwZh7N2y06+9qMN/fZ/8UOz\n+e2jDuOnT27nH37yZL/9/+38d3LMpN/i7vXP8e2V/Rfc/PqHT+aoCYfww4e38t3VW/rt/+ZH53D4\noWP4fkcXt63t7rf/+j9u45AxTdy4ajN3PPJsv/23fPx0AJbc/xQrHut9oa2xBzWx9E/aAPjGiid5\noHN7r/0Tx43hWx+bA8Df/ehx/nXLC732Tz5sLP/rwncB8Nc/XMf6rS/12n/0pEP5yvknAfD52x9h\n47ZXeu2ffdR4vvSh3wbgz29+iGdf/E2v/afMmMjn5h8PwCduXMsLu3b32v/eY5v59DnZCtUXX9fO\nb17b02v/OSccyaIzjgF87/neq8x7r+eYqsmeuyQVkKtCSlIDcVVISRrBDHdJKiDDXZIKyHCXpAIy\n3CWpgAx3SSogw12SCshwl6QCqttJTBGxDeh/rnI+zcD2QVsVi8c8MnjMI8OBHPOMlNKkwRrVLdwP\nRER05DlDq0g85pHBYx4ZanHMDstIUgEZ7pJUQI0a7kvqXUAdeMwjg8c8MlT9mBtyzF2S9NYatecu\nSXoLwzrcI2J+RGyIiM6IuHKA/QdHxC2l/Q9GREvtq6ysHMf8FxGxPiIeiYgVETGjHnVW0mDHXNbu\ngohIEdHwMyvyHHNE/GHpZ70uIr5X6xorLcd7e3pE3BMRD5Xe3+fVo85KiYjrIuL5iHh0H/sjIr5R\n+vd4JCJOqWgBKaVh+QU0AU8BRwNjgIeB2X3a/CnwrdL9C4Fb6l13DY75bGBc6f4nR8Ixl9q9Dbgf\nWA201rvuGvycZwEPARNLj4+sd901OOYlwCdL92cDm+td9wEe8xnAKcCj+9h/HnAnEMBpwIOVfP3h\n3HNvAzpTShtTSruBm4GFfdosBJaW7t8GnBMRUcMaK23QY04p3ZNS2lV6uBqYWuMaKy3Pzxngb4Cv\nAb8ZYF+jyXPMlwGLU0ovAKSUnqex5TnmBIwv3T8M2FrD+ioupXQ/sPMtmiwEbkiZ1cCEiJhcqdcf\nzuE+Begqe9xd2jZgm5TS68CLwBE1qa468hxzuUvJfvM3skGPOSLeBUxLKd1Ry8KqKM/P+TjguIh4\nICJWR8T8mlVXHXmO+cvARyOiG1gOfKo2pdXN/v5/3y+jK/VEVTBQD7zv1J48bRpJ7uOJiI8CrcCZ\nVa2o+t7ymCNiFPB14JJaFVQDeX7Oo8mGZs4i++tsZUScmFL6ZZVrq5Y8x3wRcH1K6ZqIOB24sXTM\nb1S/vLqoan4N5557NzCt7PFU+v+Z9mabiBhN9qfcW/0ZNNzlOWYi4v3AVcCClNKrNaqtWgY75rcB\nJwL3RsRmsrHJZQ3+oWre9/YPUkqvpZQ2ARvIwr5R5TnmS4FbAVJKq4CxZGuwFFWu/+9DNZzDfQ0w\nKyJmRsQYsg9Ml/Vpswy4uHT/AuAnqfRJRYMa9JhLQxTXkgV7o4/DwiDHnFJ6MaXUnFJqSSm1kH3O\nsCCl1FGfcisiz3v7X8g+PCcimsmGaTbWtMrKynPMTwPnAETECWThvq2mVdbWMuCPSrNmTgNeTCk9\nW7Fnr/cnyoN82nwe8ATZp+xXlbZdTfafG7If/veBTqAdOLreNdfgmO8GngN+XvpaVu+aq33Mfdre\nS4PPlsn5cw7gfwLrgV8AF9a75hoc82zgAbKZND8HPlDvmg/weG8CngVeI+ulXwp8AvhE2c94cenf\n4xeVfl97hqokFdBwHpaRJA2R4S5JBWS4S1IBGe6SVECGuyQVkOEuSQVkuEtSARnuklRA/x+iHIBk\nQy417wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b074d6f3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    train_data[train_data.columns[train_data.columns != 'target']]\n",
    "    , train_data['target']\n",
    "    , random_state = 1\n",
    "    , test_size = 0.2\n",
    ")\n",
    "\n",
    "cl_log = LogisticRegression()\n",
    "cl_log.fit(train_X, train_y)\n",
    "\n",
    "probs = cl_log.predict_proba(val_X)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# predict class values\n",
    "yhat = cl_log.predict(val_X)\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(val_y, probs)\n",
    "# calculate F1 score\n",
    "f1 = f1_score(val_y, yhat)\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(val_y, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0.5625, 0.5625], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
